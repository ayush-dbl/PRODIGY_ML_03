{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Define image dimensions and batch size\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayak\\Desktop\\Essentials\\Internship\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4s/step - accuracy: 0.7822 - loss: 0.4649 - val_accuracy: 0.8236 - val_loss: 0.3706\n",
      "Epoch 2/5\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayak\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8125 - loss: 0.2390 - val_accuracy: 0.8750 - val_loss: 0.1521\n",
      "Epoch 3/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - accuracy: 0.8994 - loss: 0.2566 - val_accuracy: 0.8896 - val_loss: 0.2674\n",
      "Epoch 4/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.1085 - val_accuracy: 0.9375 - val_loss: 0.0880\n",
      "Epoch 5/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4s/step - accuracy: 0.9242 - loss: 0.2066 - val_accuracy: 0.8916 - val_loss: 0.2559\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for SVM classifier\n",
    "x = Flatten()(base_model.output)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create SVM model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 110s - 2s/step - accuracy: 0.8920 - loss: 0.2543\n",
      "Test accuracy: 0.8920000195503235\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.52      1000\n",
      "           1       0.51      0.49      0.50      1000\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.51      0.51      0.51      2000\n",
      "weighted avg       0.51      0.51      0.51      2000\n",
      "\n",
      "[[524 476]\n",
      " [506 494]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(test_generator.classes, y_pred))\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "internship"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
